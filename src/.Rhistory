plot(y = dat.pca, x = c(1:7),type = "l", xaxt = "n")
c(1:7)
length(pca.dat)
pca.dat
dat.pca
summary(dat.pca)
length(dat.pca)
plot(y = dat.pca, x = c(1:5),type = "l", xaxt = "n")
plot.new()
plot(dat.pca, type = "l", xaxt = 'n', yaxt = 'n')
sink("text.txt")
"test"
sink()
"test"
getpca <- function (dat, resultPath, pcaTitle) {
# Principle Component Analysis
# Log transform
log.dat <- log(dat)
# Apply PCA
dat.pca <- prcomp(log.dat,
center = TRUE,
scale. = TRUE)
# This will pipe out put to file
sink (paste(resultPath,pcaTitle, '.txt', spep = ''), append = TRUE, split = FALSE)
summary(dat.pca)
dat.pca
# Return output to console
sink()
# Plot PCA
jpeg(paste(resultPath,pcaTitle,".jpg", sep = ""))
plot(dat.pca, type = "l", xaxt = 'n', yaxt = 'n')
title ( main = pcaTitle)
dev.off()
}
getpca(rbind(training_input, testing_input), result_path, "PCA-Monroe-County-1")
getpca(rbind(training_input, testing_input), result_path, "PCA-Monroe-County-1")
debug(getpca)
getpca(rbind(training_input, testing_input), result_path, "PCA-Monroe-County-1")
debug at #11: sink(
paste(resultPath, pcaTitle, ".txt", spep = "")
test <- paste(resultPath, pcaTitle, ".txt", spep = "")
test
.txt
".txt."
".txt"
print("a")
summary(dat.pca)
getpca <- function (dat, resultPath, pcaTitle) {
# Principle Component Analysis
# Log transform
log.dat <- log(dat)
# Apply PCA
dat.pca <- prcomp(log.dat,
center = TRUE,
scale. = TRUE)
# This will pipe out put to file
sink (paste(resultPath,pcaTitle, '.txt', sep = ''), append = TRUE, split = FALSE)
summary(dat.pca)
dat.pca
# Return output to console
sink()
# Plot PCA
jpeg(paste(resultPath,pcaTitle,".jpg", sep = ""))
plot(dat.pca, type = "l", xaxt = 'n', yaxt = 'n')
title ( main = pcaTitle)
dev.off()
}
getpca(rbind(training_input, testing_input), result_path, "PCA-Monroe-County-1")
debug(getpca)
getpca(rbind(training_input, testing_input), result_path, "PCA-Monroe-County-1")
getpca(rbind(training_input, testing_input), result_path, "PCA-Monroe-County-1")
dat.pca
dat.pca
write(dat.pca, "test.txt")
dat.pca
temp <- dat.pca
temp
temp <- as.data.frame(temp)
dat.pca
typeof(dat.pca)
as.matrix(dat.pca)
print(dat.pca)
sink ("text.txt")
print(dat.pca)
sink()
getpca <- function (dat, resultPath, pcaTitle) {
# Principle Component Analysis
# Log transform
log.dat <- log(dat)
# Apply PCA
dat.pca <- prcomp(log.dat,
center = TRUE,
scale. = TRUE)
# This will pipe out put to file
sink (paste(resultPath,pcaTitle, '.txt', sep = ''), append = TRUE, split = FALSE)
print(summary(dat.pca))
print(dat.pca)
# Return output to console
sink()
# Plot PCA
jpeg(paste(resultPath,pcaTitle,".jpg", sep = ""))
plot(dat.pca, type = "l", xaxt = 'n', yaxt = 'n')
title ( main = pcaTitle)
dev.off()
}
getpca(rbind(training_input, testing_input), result_path, "PCA-Monroe-County-1")
training_input
training_output
testing_output
testing_input
debug (runmodel)
runmodel(training_input, testing_input, "Monroe-Future-Accuracy", "test", result_path)
library(nnet)
runmodel(training_input, testing_input, "Monroe-Future-Accuracy", "test", result_path)
predicted
accuracy
?normalize
?norm
(training_input - mean(training_input) / sd(training_input))
sd(training_input)
sd(training_input[,1])
sd(training_input[,2])
sd(training_input[,3])
?apply
test <- apply (training_input,2, function(x){})
test <- apply (training_input,2, function(x){x**2})
test
test <- apply (training_input,2, function(x){(x - mean(x) / sd(x))})
test
test <- apply (training_input,2, function(x){(x - mean(x) / sd(x))})
test - training_input
training_input
test
test <- apply (training_input,1, function(x){(x - mean(x) / sd(x))})
test
t(test)
t <- training_input[,1]
t
mean(t)
t - mean(t)
sd(t)
(t - mean(t))
(t - mean(t)) / sd(t)
t <- training_input[,7]
t - mean(t)
sd(t)
(t - mean(t)) / sd(t)
(t - mean(t)) / sd(t)
test <- apply (training_input,2, function(x){(x - mean(x) / sd(x))})
test[,1]
test
test[,1]
plot(test[,1])
print(test)
View(test)
a <- apply (training_input,2, function(x){(x - mean(x) / sd(x))})
a
a[,1]
a <- apply (training_input,2, function(x){(x - mean(x) / sd(x))})
training_input
a
a[,7]
test[,7]
debug(apply)
a <- apply (training_input,2, function(x){(x - mean(x) / sd(x))})
dn.ans
d2
newX
newX
newX
dimnames()
newX
tmp
ans
ans.list
ans.names
ans.list
str(training_input)
normalized <- apply(training_input, 2, function(x) {
((x - mean(x)) / sd(x) )
})
normalized
source('model.r')
source('Model-Functions.r')
data_path <- '../data/county/'
result_path <- '../results/Monroe/'
## Load in response variables
sold_for_gain <- read.csv( file = paste(data_path, 'County_PctOfHomesSellingForGain_AllHomes.csv', sep = ''))
sold_for_gain <- sold_for_gain[sold_for_gain$Metro == 'Rochester',]
sold_for_gain <- t(subset(sold_for_gain, select = X2010.10:X2015.09))
increasing_in_value <- read.csv ( file = paste(data_path, 'County_PctOfHomesIncreasingInValues_AllHomes.csv', sep =''))
increasing_in_value <- increasing_in_value[increasing_in_value$Metro == 'Rochester',]
increasing_in_value <- increasing_in_value[increasing_in_value$RegionName == 'Monroe',]
increasing_in_value <- t(subset(increasing_in_value, select = X2010.10:X2015.09))
pct_price_reduced <-read.csv ( file = paste(data_path, 'County_PctOfListingsWithPriceReductions_AllHomes.csv', sep = ''))
pct_price_reduced <- pct_price_reduced[pct_price_reduced$RegionName == 'Monroe',]
pct_price_reduced <- pct_price_reduced[pct_price_reduced$State == 'NY',]
pct_price_reduced <- t(subset(pct_price_reduced, select = X2010.10:X2015.09))
median_pct_price_reduced <-read.csv ( file = paste(data_path, 'County_MedianPctOfPriceReduction_AllHomes.csv', sep = ''))
median_pct_price_reduced <- median_pct_price_reduced[median_pct_price_reduced$RegionName == 'Monroe',]
median_pct_price_reduced <- median_pct_price_reduced[median_pct_price_reduced$State == 'NY',]
median_pct_price_reduced <- t(subset(median_pct_price_reduced, select = X2010.10:X2015.09))
ratio_foreclose <- read.csv ( file = paste(data_path, 'County_HomesSoldAsForeclosures-Ratio_AllHomes.csv', sep = ''))
ratio_foreclose <- ratio_foreclose [ratio_foreclose$RegionName == 'Monroe',]
ratio_foreclose <- ratio_foreclose [ratio_foreclose$Metro == 'Rochester',]
ratio_foreclose <- t(subset(ratio_foreclose, select = X2010.10:X2015.09))
inventory_measure <- read.csv ( file = paste(data_path, 'InventoryMeasure_County_Public.csv', sep = ''))
inventory_measure <- inventory_measure [inventory_measure$CountyName == 'Monroe',]
inventory_measure <- inventory_measure [inventory_measure$Metro == 'Rochester',]
inventory_measure <- t(subset(inventory_measure, select = X2010.10:X2015.09))
price_to_rent = read.csv(file = paste(data_path, 'County_PriceToRentRatio_AllHomes.csv', sep = ''))
price_to_rent <- price_to_rent[price_to_rent$RegionName == 'Monroe',]
price_to_rent <- price_to_rent[price_to_rent$State == 'NY',]
price_to_rent <- t(subset(price_to_rent, select = X2010.10:X2015.09))
# Target Variable
median_sold_price <- read.csv( file = paste(data_path, 'County_MedianSoldPrice_AllHomes.csv', sep = ''))
median_sold_price <- median_sold_price[median_sold_price$Metro == 'Rochester',]
median_sold_price <- median_sold_price[median_sold_price$RegionName == 'Monroe',]
median_sold_price <- t(subset(median_sold_price, select = X2010.10:X2015.09))
# Create array of columns names used for dataframe
names <- c('ratio_foreclose', 'inventory_measure','price_to_rent','sold_for_gain',
'increasing_in_value', 'pct_price_reduced','median_sold_price' )
# Bind all of the features into a dataframe
housing_dat = as.data.frame(cbind(ratio_foreclose, inventory_measure,price_to_rent,
sold_for_gain,increasing_in_value,pct_price_reduced,median_sold_price))
# Prepare training and testing data
prepared_data <- prepdata(housing_dat, names)
training_input <- as.data.frame(prepared_data[1])
testing_input <- as.data.frame(prepared_data[2])
testing_input
median_sold_price
prepared_data
debug(prepData)
debug(prepdata)
prepared_data <- prepdata(housing_dat, names)
dat
prepared_data <- prepdata(housing_dat, names)
undebug(prepdata)
# file: Model-Functions.r
# Contributers: William Hammond
#               Harry Longwell
# Created: 11/19/2015
# Modified: 11/22/2015
library(nnet)
# Function that computes and plots PCA for a given data set.
# Input:
#       dat = data set
#       resultPath = Path to results folder
#       pcaTitle = title to plot
getpca <- function (dat, resultPath, pcaTitle) {
# Principle Component Analysis
# Log transform
log.dat <- log(dat)
# Apply PCA
dat.pca <- prcomp(log.dat,
center = TRUE,
scale. = TRUE)
# This will pipe out put to file
sink (paste(resultPath,pcaTitle, '.txt', sep = ''), append = TRUE, split = FALSE)
print(summary(dat.pca))
print(dat.pca)
# Return output to console
sink()
# Plot PCA
jpeg(paste(resultPath,pcaTitle,".jpg", sep = ""))
plot(dat.pca, type = "l", xaxt = 'n', yaxt = 'n')
title ( main = pcaTitle)
dev.off()
}
# Function that prepares the data to put into the neural network. We bind the
# data leaving the target variable in the right most column. Every column
# corresponds to a different feature. Features are normalized using z-score
#
# Input:
#       dat = data set, last column must be th target variable
#       sizeTrainging = The percent of the data we want to train on
#       datanames = array of names that correspond to feature names
#       shuffle = if TRUE shuffle rowise, if false leave in time order
prepdata <- function(dat,dataNames,sizeTraining = 0.8,  shuffle = FALSE) {
# Set column names
colnames(dat) <- dataNames
# Shuffle row-wise if need be
if (shuffle == TRUE){
dat <- dat[sample(nrow(dat)),]
}
dat <- apply(dat, 2, function(x) {
((x - mean(x)) / sd(x) )
})
# Get the number of data points
num_data <- dim(dat)[1]
# Find training and testing size
training_size <- num_data * sizeTraining
testing_size <- num_data * (1 - sizeTraining)
# Divid training and testing set
train_input <- dat[1:training_size,]
test_input <- dat[(training_size + 1):(training_size + testing_size),]
# Remove any row that has an NA in it
train_input <- train_input[complete.cases(train_input),]
test_input <- test_input[complete.cases(test_input),]
return (list(train_input, test_input))
}
# Trains neural network, runs prediction and creates visualizations
# Input:
#       trainInput = training input
#       shuffle = if TRUE change title to reflect the fact data is shuffled
runmodel <- function (trainInput, testInput,  accuracyTitle, residualTitle, resultPath) {
model_nnet <- nnet(x=as.data.frame(trainInput[,1:ncol(trainInput) - 1]), hidden = 10,
y=as.data.frame(trainInput[,ncol(trainInput)]), size=20,maxit = 10000, linout = TRUE,
trace = TRUE, decay=1e-3)
# Run Prediction
predicted <- predict(model_nnet, testInput, type = "raw")
# Compute Accuracy
accuracy <- (((predicted-testInput)/testInput)*100)[,ncol(trainInput)]
# Find the range we want to limit the plot to
bounds <- max(abs(ceiling(max(accuracy))),abs(floor(min(accuracy))))
# Create name of the output file
accuracy_file_name <- paste(resultPath,accuracyTitle, '.jpg', sep = "")
# Plot and save accuracy
jpeg (accuracy_file_name)
plot(accuracy, ylim = c(-bounds,bounds), ylab = "Percent",
xlab = "Year and Month (10/2014 - 09/2015)")
title (main = accuracyTitle)
dev.off()
}
prepared_data <- prepdata(housing_dat, names)
debug(prepdata)
prepared_data <- prepdata(housing_dat, names)
dat
prepdata <- function(dat,dataNames,sizeTraining = 0.8,  shuffle = FALSE) {
# Set column names
colnames(dat) <- dataNames
# Remove any row that has NA in it
dat <- dat[complete.cases(dat),]
# Shuffle row-wise if need be
if (shuffle == TRUE){
dat <- dat[sample(nrow(dat)),]
}
dat <- apply(dat, 2, function(x) {
((x - mean(x)) / sd(x) )
})
# Get the number of data points
num_data <- dim(dat)[1]
# Find training and testing size
training_size <- num_data * sizeTraining
testing_size <- num_data * (1 - sizeTraining)
# Divid training and testing set
train_input <- dat[1:training_size,]
test_input <- dat[(training_size + 1):(training_size + testing_size),]
return (list(train_input, test_input))
}
prepared_data <- prepdata(housing_dat, names)
training_input <- as.data.frame(prepared_data[1])
testing_input <- as.data.frame(prepared_data[2])
prepared_data
getpca(rbind(training_input, testing_input), result_path, "PCA-Monroe-County-1")
training_input
runmodel(training_input, testing_input, "Monroe-Future-Accuracy", "test", result_path)
debug(runmodel)
runmodel(training_input, testing_input, "Monroe-Future-Accuracy", "test", result_path)
accuracy
model_nnet$fitted.values
getpca(rbind(training_input, testing_input), result_path, "PCA-Monroe-County-1")
debug(getpca)
getpca(rbind(training_input, testing_input), result_path, "PCA-Monroe-County-1")
getpca(rbind(training_input, testing_input), result_path, "PCA-Monroe-County-1")
log.dat
dat
log(dat)
log(.1)
log(0)
log(0.00001)
log(-1)
prepdata <- function(dat,dataNames,normalization = "n",sizeTraining = 0.8,  shuffle = FALSE) {
# Set column names
colnames(dat) <- dataNames
# Remove any row that has NA in it
dat <- dat[complete.cases(dat),]
if (nomralization == "z") {
dat <- apply(dat, 2, function(x) {
((x - mean(x)) / sd(x) )
})
}
else if (normalization ==  "mm") {
dat <- apply(dat, 2, function(x) {
((x - min(x)) / (max(x) - min(x)) )
})
}
# Shuffle row-wise if need be
if (shuffle == TRUE){
dat <- dat[sample(nrow(dat)),]
}
# Get the number of data points
num_data <- dim(dat)[1]
# Find training and testing size
training_size <- num_data * sizeTraining
testing_size <- num_data * (1 - sizeTraining)
# Divid training and testing set
train_input <- dat[1:training_size,]
test_input <- dat[(training_size + 1):(training_size + testing_size),]
return (list(train_input, test_input))
}
getpca(prepdata(housing_dat,names, normalization = "mm"), result_path, "PCA-Monroe-County-1")
undebug(getpca)
prepdata <- function(dat,dataNames,normalization = "n",sizeTraining = 0.8,  shuffle = FALSE) {
# Set column names
colnames(dat) <- dataNames
# Remove any row that has NA in it
dat <- dat[complete.cases(dat),]
if (normalization == "z") {
dat <- apply(dat, 2, function(x) {
((x - mean(x)) / sd(x) )
})
}
else if (normalization ==  "mm") {
dat <- apply(dat, 2, function(x) {
((x - min(x)) / (max(x) - min(x)) )
})
}
# Shuffle row-wise if need be
if (shuffle == TRUE){
dat <- dat[sample(nrow(dat)),]
}
# Get the number of data points
num_data <- dim(dat)[1]
# Find training and testing size
training_size <- num_data * sizeTraining
testing_size <- num_data * (1 - sizeTraining)
# Divid training and testing set
train_input <- dat[1:training_size,]
test_input <- dat[(training_size + 1):(training_size + testing_size),]
return (list(train_input, test_input))
}
getpca(prepdata(housing_dat,names, normalization = "mm"), result_path, "PCA-Monroe-County-1")
test = prepdata(housing_dat,names, normalization = "mm"
)
test
log(test)
prepdata <- function(dat,dataNames,normalization = "n",sizeTraining = 0.8,  shuffle = FALSE, split = FALSE) {
# Set column names
colnames(dat) <- dataNames
# Remove any row that has NA in it
dat <- dat[complete.cases(dat),]
if (normalization == "z") {
dat <- apply(dat, 2, function(x) {
((x - mean(x)) / sd(x) )
})
}
else if (normalization ==  "mm") {
dat <- apply(dat, 2, function(x) {
((x - min(x)) / (max(x) - min(x)) )
})
}
# Shuffle row-wise if need be
if (shuffle == TRUE){
dat <- dat[sample(nrow(dat)),]
}
# Divid training and testing set
if (split == TRUE) {
# Get the number of data points
num_data <- dim(dat)[1]
# Find training and testing size
training_size <- num_data * sizeTraining
testing_size <- num_data * (1 - sizeTraining)
train_input <- dat[1:training_size,]
test_input <- dat[(training_size + 1):(training_size + testing_size),]
return (list(train_input, test_input))
} else {
return (dat)
}
}
getpca(prepdata(housing_dat,names, normalization = "mm"), result_path, "PCA-Monroe-County-1")
debug(getpca)
getpca(prepdata(housing_dat,names, normalization = "mm"), result_path, "PCA-Monroe-County-1")
test = prepdata(housing_dat,names, normalization = "mm")
test
log(test)
getpca(prepdata(housing_dat,names), result_path, "PCA-Monroe-County-1")
getpca(prepdata(housing_dat,names), result_path, "PCA-Monroe-County-foreclose+inventory")
undeug(getpca)
undebug(getpca)
runmodel(training_input, testing_input, "Monroe-Future-Accuracy-foreclose+inventory", "test", result_path)
undebug(runmodel)
names <- c('price_to_rent','sold_for_gain',
'increasing_in_value', 'pct_price_reduced','median_sold_price' )
# Bind all of the features into a dataframe
housing_dat = as.data.frame(cbind(price_to_rent,sold_for_gain,increasing_in_value,pct_price_reduced,median_sold_price))
# Run PCA
getpca(prepdata(housing_dat,names), result_path, "PCA-Monroe-County-foreclose+inventory")
# Prepare training and testing data
prepared_data <- prepdata(housing_dat, names, normalization = "z")
training_input <- as.data.frame(prepared_data[1])
testing_input <- as.data.frame(prepared_data[2])
# Run the model and save the results
runmodel(training_input, testing_input, "Monroe-Future-Accuracy-foreclose+inventory", "test", result_path)
debug(runmodel)
runmodel(training_input, testing_input, "Monroe-Future-Accuracy-foreclose+inventory", "test", result_path)
predicted
testInput
trainInput
housing_dat
prepared_data <- prepdata(housing_dat, names, normalization = "z")
prepared_data
training_input <- as.data.frame(prepared_data[1])
testing_input <- as.data.frame(prepared_data[2])
trainint_input
training_input
prepared_data <- prepdata(housing_dat, names, normalization = "z", split = TRUE)
training_input <- as.data.frame(prepared_data[1])
testing_input <- as.data.frame(prepared_data[2])
training_input
runmodel(training_input, testing_input, "Monroe-Future-Accuracy", "test", result_path)
accuracy
